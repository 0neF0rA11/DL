{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Z51XDM6vwka"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import List, Dict\n",
        "import torch\n",
        "\n",
        "from zipfile import ZipFile\n",
        "from urllib.request import urlretrieve\n",
        "\n",
        "from IPython.display import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](attachment:image.png)"
      ],
      "metadata": {
        "id": "tfdyYcv4csWe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open('Библиотека/avtostrax/inference/assets/annotations_details_train_panoptic_fake.json', 'r') as f:\n",
        "    details = json.loads(f.read())\n",
        "details_codes = [detail['id'] for detail in details['categories']]"
      ],
      "metadata": {
        "id": "3X7UA7e6cuut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Функция считывания изображений\n",
        "def read_images(path_to_pkl: str):\n",
        "    data = joblib.load(path_to_pkl)\n",
        "    keys = list(data.keys())\n",
        "    return data, keys"
      ],
      "metadata": {
        "id": "WWtSdyuQcw8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images_info, paths = read_images(\"/storage/workflow/Datasets_local/temp_crop_0_1_0/detail_predictions_1639623656.pkl\")"
      ],
      "metadata": {
        "id": "6brRMM57c0C5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CATEGORIES = [2, 8, 75, 76]\n",
        "PERCANT_STATE = 15\n",
        "WINDOW_H = 180\n",
        "WINDOW_W = int(WINDOW_H * 16 / 9)\n",
        "STEP = 30"
      ],
      "metadata": {
        "id": "E9Th89gMc1pM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cropping_imgs(path: str, mask, key: List[Dict], details_codes: List[int], CATEGORIES: List, CROPP_SIZE: List):\n",
        "    '''\n",
        "    Функция для кроппа изображений\n",
        "\n",
        "    Параметры на вход:\n",
        "        path: путь до изображения\n",
        "        mask: маска изображения\n",
        "        key: кодировка изображений (labeling)\n",
        "        details_codes: истинная кодировка деталей\n",
        "        CATEGORIES: Категории (минимум одна), которые должны быть в кроппинге\n",
        "        CROPP_SIZE: итоговый размер кроппа (после расширения)\n",
        "\n",
        "    Промежуточные итоги: Нарезка примерных изображений\n",
        "    '''\n",
        "\n",
        "    WINDOW_H = int(mask.size()[0] * 0.5) // 9 * 9\n",
        "    WINDOW_W = int(WINDOW_H * 16 / 9)\n",
        "    STEP_H = int(WINDOW_H *0.5)\n",
        "    STEP_W = int(WINDOW_W *0.3)\n",
        "\n",
        "    new_data = {}\n",
        "\n",
        "    details_category_indexes = [details_codes.index(category) for category in CATEGORIES]\n",
        "    needed_key_id = [item['id'] for item in key if item['category_id'] in details_category_indexes]\n",
        "\n",
        "    PERCANT_STATE = sum([torch.sum(mask == item) for item in needed_key_id])/(mask.shape[0]*mask.shape[1])*125\n",
        "\n",
        "    # Кодировка раскодировка\n",
        "    id_to_category_in_key = {item['id']: item['category_id'] for item in key}\n",
        "\n",
        "    # Увеличение нижней границы (мб поможет с центровкой камеры)\n",
        "    zeros_tensor = torch.zeros(int(WINDOW_H*0.3), mask.size()[1])\n",
        "    mask = torch.cat((mask, zeros_tensor), dim=0)\n",
        "\n",
        "    result_tensors = []\n",
        "    count_photo = 1\n",
        "\n",
        "    #подумать над архивом\n",
        "    image = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "    image = image[:, :, ::-1]\n",
        "\n",
        "    for i in range(0, mask.shape[0] - WINDOW_H + 1, STEP_H):\n",
        "        for j in range(0, mask.shape[1] - WINDOW_W + 1, STEP_W):\n",
        "            # Границы окна\n",
        "            x_beg, x_end = j, j+WINDOW_W\n",
        "            y_beg, y_end = i, i+WINDOW_H\n",
        "\n",
        "            window_mask = mask[y_beg:y_end, x_beg:x_end]\n",
        "            # Проверка на нахождение нужных категорий на кропе\n",
        "            check_list = [1 if item in window_mask.unique() else 0 for item in needed_key_id]\n",
        "            percentages_of_categories_on_cropp = [torch.sum(window_mask == item)/(WINDOW_H*WINDOW_W)*100 for item in needed_key_id]\n",
        "\n",
        "            percentages_of_background_down = torch.sum(torch.all(window_mask == 0, dim=1))/WINDOW_H*100\n",
        "\n",
        "            # Условие отбора:\n",
        "            if window_mask.unique().shape[0] > 3 and sum(check_list) > 1 and 10 < percentages_of_background_down < 50 and sum(percentages_of_categories_on_cropp) > PERCANT_STATE:\n",
        "\n",
        "                # Создание новой data; пойдет в pkl\n",
        "                new_key = []\n",
        "                clone_wm = window_mask.clone()\n",
        "                for new_id, old_id in enumerate(clone_wm.unique()[1:], start=1):\n",
        "                    new_key.append({'id': new_id, 'isthing': True, 'category_id': id_to_category_in_key[old_id.item()]})\n",
        "                    clone_wm[clone_wm == old_id] = new_id\n",
        "\n",
        "\n",
        "                cropped_img = image[y_beg:y_end, x_beg:x_end]\n",
        "                resized_cropped_img = cv2.resize(cropped_img, CROPP_SIZE)\n",
        "                resized_clone_wm = torch.tensor(cv2.resize(clone_wm.numpy(), CROPP_SIZE))\n",
        "\n",
        "                plt.imshow(resized_cropped_img)\n",
        "                plt.show()\n",
        "\n",
        "                plt.imshow(resized_clone_wm)\n",
        "                plt.show()\n",
        "                # Изменить size clone_wm\n",
        "                data_value = (resized_clone_wm, new_key)\n",
        "\n"
      ],
      "metadata": {
        "id": "w7WXxk9sc5Fc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for path in paths:\n",
        "    mask, key = images_info[path]\n",
        "    cropping_imgs(path, mask, key, details_codes, WINDOW_H, WINDOW_W, STEP, CATEGORIES, PERCANT_STATE)\n",
        "    break"
      ],
      "metadata": {
        "id": "7Wyotixdc7l0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/storage/workflow/Datasets_local/damage_spoiler_0_1_0/cases/\"\n",
        "folders = glob.glob(path + \"*/\")\n",
        "\n",
        "# Сортируем папки по дате создания\n",
        "folders.sort(key=lambda x: os.path.getctime(x))\n",
        "\n",
        "idx_photo = 0\n",
        "list_paths = []\n",
        "\n",
        "for count, folder in enumerate(folders[10:]):\n",
        "    if count == 20:\n",
        "        break\n",
        "\n",
        "    case = folder.split('/')[-2]\n",
        "    print(f\"Case: {case}\\n\")\n",
        "    list_paths.extend(glob.glob(f'{folder}*.jpg'))\n",
        "    for file in glob.glob(f'{folder}*.jpg'):\n",
        "        print(idx_photo, file)\n",
        "        image = Image.open(file)\n",
        "        display(image)\n",
        "        idx_photo += 1\n",
        "    print()"
      ],
      "metadata": {
        "id": "FZaoDSLfzIrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx in true_indexes:\n",
        "    file_name = list_paths[idx]\n",
        "\n",
        "    folder = file_name.split('/')[-2]\n",
        "\n",
        "    # Куда копируем\n",
        "    destination_folder = '/storage/workflow/Datasets_local/damage_spoiler_0_2_0/cases/' + folder + '/'\n",
        "\n",
        "    if not os.path.exists(destination_folder):\n",
        "        os.makedirs(destination_folder)\n",
        "\n",
        "    shutil.copy(file_name, destination_folder)"
      ],
      "metadata": {
        "id": "BvCNjfikzRdS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}